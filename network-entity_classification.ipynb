{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#device = 0\n",
    "#torch.cuda.set_device(device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "#https://github.com/FAU-DLM/python-wsi-preprocessing\n",
    "sys.path.append('../preprocessing_pipeline/python-wsi-preprocessing/')\n",
    "import wsi\n",
    "from wsi import tiles, util\n",
    "\n",
    "sys.path.append('../fastai/')\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.callbacks import *\n",
    "\n",
    "sys.path.append('../models-pytorch/pretrained-models.pytorch')\n",
    "import pretrainedmodels\n",
    "from pretrainedmodels import *\n",
    "\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import *\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "from functools import partial, update_wrapper\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from typing import List, Callable\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 10000000000   \n",
    "\n",
    "PATH = Path('/home/Deep_Learner/private/datasets/Hypophysenadenome/')\n",
    "\n",
    "WSIS_CORTICOTROP = PATH/'corticotrop'\n",
    "WSIS_GONADOTROP = PATH/'gonadotrop'\n",
    "\n",
    "ROIS_CORTICOTROP = PATH/'corticotrop_ROIs'\n",
    "ROIS_GONADOTROP = PATH/'gonadotrop_ROIs'\n",
    "\n",
    "TILES_CORTICOTROP_1 = PATH/'tiles_corticotrop_1_scoring_function_1_thresh_0.55'\n",
    "TILES_CORTICOTROP_2 = PATH/'tiles_corticotrop_2_scoring_function_1_thresh_0.55'\n",
    "TILES_CORTICOTROP_3 = PATH/'tiles_corticotrop_3_scoring_function_1_thresh_0.4'\n",
    "\n",
    "TILES_GONADOTROP_1 = PATH/'tiles_gonadotrop_1_scoring_function_1_thresh_0.55'\n",
    "TILES_GONADOTROP_2 = PATH/'tiles_gonadotrop_2_scoring_function_1_thresh_0.55'\n",
    "TILES_GONADOTROP_3 = PATH/'tiles_gonadotrop_3_scoring_function_1_thresh_0.4'\n",
    "\n",
    "#TEST = PATH/TEST_NAME\n",
    "#TEST = PATH_LOCAL/TEST_NAME\n",
    "TEST_EXPERIMENTING = PATH/'tiles_test_100_for_testing'\n",
    "LABELS_CORTICOTROP_NAME = 'KortikotropHA_gelabled.xlsx'\n",
    "LABELS_CORTICOTROP = PATH/LABELS_CORTICOTROP_NAME\n",
    "LABELS_GONADOTROP_NAME = 'GonadotropeHA_gelabled.xlsx'\n",
    "LABELS_GONADOTROP = PATH/LABELS_GONADOTROP_NAME\n",
    "MODEL_PATH_NAME = 'models'\n",
    "MODEL_PATH = PATH/MODEL_PATH_NAME\n",
    "\n",
    "ROIS_EXPERIMENTING = PATH/'rois_experimenting'\n",
    "TILES_EXPERIMENTING = PATH/'tiles_experimenting'\n",
    "\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "#def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n",
    "#        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "#        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "#        x = self.one_batch(ds_type=DatasetType.Train, denorm=False)[0].cpu()\n",
    "#        return [func(channel_view(x), 1) for func in funcs]\n",
    "#        \n",
    "#vision.data.ImageDataBunch.batch_stats = batch_stats\n",
    "\n",
    "sz = 512\n",
    "bs = 6\n",
    "\n",
    "#fastai defaults\n",
    "tta_beta = 0.4 \n",
    "tta_scale = 1.35\n",
    "dropout = 0.5\n",
    "wd = 0.01\n",
    "\n",
    "#non defaults\n",
    "#wd = 0.1 not better for se_resnext50\n",
    "#dropout = 0.9\n",
    "\n",
    "\n",
    "seed = 19\n",
    "np.random.seed(seed)\n",
    "\n",
    "num2lbs = {\n",
    "    0:\"corticotrop\", \n",
    "    3:\"silent\",  \n",
    "    8:\"LH\", \n",
    "    9:\"FSH\"\n",
    "}\n",
    "\n",
    "lbs2num = {l:n for n,l in num2lbs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import flatten_model\n",
    "\n",
    "def arch_summary(arch):\n",
    "    model = arch(False)\n",
    "    tot = 0\n",
    "    for i, l in enumerate(model.children()):\n",
    "        n_layers = len(flatten_model(l))\n",
    "        tot += n_layers\n",
    "        print(f'({i}) {l.__class__.__name__:<12}: {n_layers:<4}layers (total: {tot})')\n",
    "\n",
    "def show(np):\n",
    "    return util.np_to_pil(np)\n",
    "\n",
    "Path.ls = lambda x: [p for p in list(x.iterdir()) if '.ipynb_checkpoints' not in p.name]\n",
    "\n",
    "def show_multiple_images(path, rows = 3, figsize=(128, 64)):\n",
    "    imgs = [open_image(p) for p in path.ls()]\n",
    "    show_all(imgs=imgs, r=rows, figsize=figsize)\n",
    "    \n",
    "def show_multiple_images_big(path:pathlib.Path):\n",
    "    for p in path.ls():\n",
    "        plt.imshow(mpimg.imread(str(p)))\n",
    "        plt.show()\n",
    "        \n",
    "def get_id_from_path(path):\n",
    "    path = Path(path)\n",
    "    split = path.stem.split('-')\n",
    "    return f'{split[0]}-{split[1]}'\n",
    "\n",
    "def get_slide_name_from_path(path):\n",
    "    path = Path(path)\n",
    "    split = path.stem.split('-')\n",
    "    try:\n",
    "        return f'{split[0]}-{split[1]}-{split[2]}-{split[3]}'\n",
    "    except IndexError:\n",
    "        return f'{split[0]}-{split[1]}-{split[2]}'\n",
    "    \n",
    "def extract_case_ids_from_existing_tiles()->tuple((List[str], List[pathlib.Path])):\n",
    "    tile_paths_gonadotrop_1 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_GONADOTROP_1.ls()) if p.suffix == '.png']\n",
    "    tile_paths_gonadotrop_2 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_GONADOTROP_2.ls()) if p.suffix == '.png']\n",
    "    tile_paths_gonadotrop_3 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_GONADOTROP_3.ls()) if p.suffix == '.png']\n",
    "    \n",
    "    tile_paths_corticotrop_1 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_CORTICOTROP_1.ls()) if p.suffix == '.png']\n",
    "    tile_paths_corticotrop_2 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_CORTICOTROP_2.ls()) if p.suffix == '.png']\n",
    "    tile_paths_corticotrop_3 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_CORTICOTROP_3.ls()) if p.suffix == '.png']\n",
    "    \n",
    "    tile_paths_all = tile_paths_gonadotrop_1 \\\n",
    "                        + tile_paths_gonadotrop_2 \\\n",
    "                        + tile_paths_gonadotrop_3 \\\n",
    "                        + tile_paths_corticotrop_1 \\\n",
    "                        + tile_paths_corticotrop_2 \\\n",
    "                        + tile_paths_corticotrop_3 \\\n",
    "    \n",
    "    return list(set([get_id_from_path(p) for p in tile_paths_all])), tile_paths_all\n",
    "\n",
    "\n",
    "df_c = pd.read_excel(LABELS_CORTICOTROP)\n",
    "def label_func(path):\n",
    "    path = Path(path)\n",
    "    s = path.stem  \n",
    "    if('LH+FSH' in s):\n",
    "        return [lbs2num['LH'],lbs2num['FSH']]\n",
    "    elif 'LH' in s:       \n",
    "        return [lbs2num['LH']]\n",
    "    elif 'FSH' in s:        \n",
    "        return [lbs2num['FSH']]\n",
    "    elif 'ACTH' in s:\n",
    "        result = [lbs2num['corticotrop']]\n",
    "        id = get_id_from_path(path)\n",
    "        l = df_c.loc[df_c.id == id].label\n",
    "        try:\n",
    "            if str(lbs2num['silent']) in str(l.values[0]):\n",
    "                result.append(3)\n",
    "        except:\n",
    "            print(l.values)\n",
    "            print(s)\n",
    "            print(get_id_from_path(path))\n",
    "            raise\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/PPPW/deep-learning-random-explore/blob/master/CNN_archs/cnn_archs.ipynb\n",
    "\n",
    "def identity(x): return x\n",
    "\n",
    "def nasnetamobile(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.nasnetamobile(pretrained=pretrained, num_classes=1000)  \n",
    "    model.logits = identity\n",
    "    model_meta[nasnetamobile] =  { 'cut': identity, 'split': lambda m: (list(m[0][0].children())[8], m[1]) }\n",
    "    return nn.Sequential(model)\n",
    "\n",
    "#arch_summary(lambda _: nasnetamobile(False)[0])\n",
    "\n",
    "def se_resnext50_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    model_meta[se_resnext50_32x4d] =  {'cut': -2, 'split': lambda m: (m[0][3], m[1]) }\n",
    "    return model\n",
    "\n",
    "#arch_summary(lambda _: pretrainedmodels.se_resnext50_32x4d(pretrained=None))\n",
    "\n",
    "def se_resnext101_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext101_32x4d(pretrained=pretrained)\n",
    "    model_meta[se_resnext101_32x4d] =  {'cut': -2, 'split': lambda m: (m[0][3], m[1]) }\n",
    "    return model\n",
    "\n",
    "def xception(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.xception(pretrained=pretrained)\n",
    "    model_meta[xception] =  { 'cut': -1, 'split': lambda m: (m[0][11], m[1]) }\n",
    "    return model\n",
    "\n",
    "def inceptionv4(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.inceptionv4(pretrained=pretrained)\n",
    "    model_meta[xception] =  { 'cut': -2, 'split': lambda m: (m[0][11], m[1]) }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n='test'\n",
    "\n",
    "n = np.load('n.npy')\n",
    "print(n)\n",
    "\n",
    "m = n+1\n",
    "m=13\n",
    "np.save('n', m)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Some numbers of the dataset (not necessary for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### check for possible mistakes in label function\n",
    "for tile_p in tile_paths_all:\n",
    "    lbl = label_func(tile_p)\n",
    "    if (0 in lbl or 3 in lbl) and (8 in lbl or 9 in lbl):\n",
    "        print(tile_p)\n",
    "        print(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acth_tiles = 0\n",
    "silent_acth_tiles = 0\n",
    "lh_tiles = 0\n",
    "fsh_tiles = 0\n",
    "gonadotropic_tiles = 0\n",
    "acth_cases = 0\n",
    "silent_acth_cases = 0\n",
    "lh_cases = 0\n",
    "fsh_cases = 0\n",
    "gonadotropic_cases = 0\n",
    "\n",
    "case_ids_visited = []\n",
    "\n",
    "for tile_path in tile_paths_all:\n",
    "    lbl = label_func(tile_path)\n",
    "    case_id = get_id_from_path(tile_path)\n",
    "    if 0 in lbl:\n",
    "        acth_tiles += 1\n",
    "        if case_id not in case_ids_visited:\n",
    "            acth_cases += 1\n",
    "    if 3 in lbl:\n",
    "        silent_acth_tiles += 1\n",
    "        if case_id not in case_ids_visited:\n",
    "            silent_acth_cases += 1\n",
    "    if 8 in lbl:\n",
    "        lh_tiles += 1\n",
    "        if case_id not in case_ids_visited:\n",
    "            lh_cases += 1\n",
    "    if 9 in lbl:\n",
    "        fsh_tiles += 1\n",
    "        if case_id not in case_ids_visited:\n",
    "            fsh_cases += 1\n",
    "    if 8 in lbl or 9 in lbl:\n",
    "        gonadotropic_tiles += 1\n",
    "        if case_id not in case_ids_visited:\n",
    "            gonadotropic_cases += 1\n",
    "    if case_id not in case_ids_visited:\n",
    "        case_ids_visited.append(case_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(case_ids_visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(case_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'tiles with label \"acth\": {acth_tiles/len(tile_paths_all)*100}%')\n",
    "print(f'tiles with label \"silent_acth\": {silent_acth_tiles/len(tile_paths_all)*100}%')\n",
    "print(f'tiles with label \"lh\": {lh_tiles/len(tile_paths_all)*100}%')\n",
    "print(f'tiles with label \"fsh\": {fsh_tiles/len(tile_paths_all)*100}%')\n",
    "print(f'tiles with label \"lh or fsh\": {gonadotropic_tiles/len(tile_paths_all)*100}%')\n",
    "print(f'cases with label \"acth\": {acth_cases/len(case_ids)*100}%')\n",
    "print(f'cases with label \"silent_acth\": {silent_acth_cases/len(case_ids)*100}%')\n",
    "print(f'cases with label \"lh\": {lh_cases/len(case_ids)*100}%')\n",
    "print(f'cases with label \"fsh\": {fsh_cases/len(case_ids)*100}%')\n",
    "print(f'cases with label \"lh or fsh\": {gonadotropic_cases/len(case_ids)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### gonadotropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# H&E and immunos\n",
    "all_wsis_paths_gonado = [p for p in WSIS_GONADOTROP.ls() if p.suffix == '.ndpi']; len(all_wsis_paths_gonado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all gonadotropic HE WSIs\n",
    "\n",
    "wsi_names_gon = set([p for p in WSIS_GONADOTROP.ls() \n",
    "                     if ('HE' in str(p) \\\n",
    "                     and not ('LH' in str(p) or 'FSH' in str(p)) \\\n",
    "                     and p.suffix == '.ndpi')])\n",
    "print(len(wsi_names_gon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all gonadotropic cases == number of patients (one case per patient)\n",
    "len(set([get_id_from_path(p) for p in WSIS_GONADOTROP.ls()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of cases, ROIs have been extracted from\n",
    "len(set([get_id_from_path(p) for p in ROIS_GONADOTROP.ls()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of ROIs\n",
    "len(ROIS_GONADOTROP.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tile_paths_gonadotrop_1 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_GONADOTROP_1.ls()) if p.suffix == '.png']\n",
    "tile_paths_gonadotrop_2 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_GONADOTROP_2.ls()) if p.suffix == '.png']\n",
    "tile_paths_gonadotrop_3 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_GONADOTROP_3.ls()) if p.suffix == '.png']\n",
    "tile_paths_all_gonadotrop = tile_paths_gonadotrop_1 \\\n",
    "                            + tile_paths_gonadotrop_2 \\\n",
    "                            + tile_paths_gonadotrop_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of cases, tiles have been extracted from\n",
    "len(set([get_id_from_path(p) for p in tile_paths_all_gonadotrop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tile_paths_all_gonadotrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### corticotropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# H&E and immunos\n",
    "all_wsis_paths_cortico = [p for p in WSIS_CORTICOTROP.ls() if p.suffix == '.ndpi']; len(all_wsis_paths_cortico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all corticotropic HE WSIs\n",
    "wsi_names_cort = set([p for p in WSIS_CORTICOTROP.ls() if ('HE' in str(p) and not 'ACTH' in str(p) and p.suffix == '.ndpi')])\n",
    "print(len(wsi_names_cort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all corticotropic cases == number of patients (one case per patient, but some cases have more than one HE WSI)\n",
    "len(set([get_id_from_path(p) for p in WSIS_CORTICOTROP.ls()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of cases, ROIs have been extracted from\n",
    "len(set([get_id_from_path(p) for p in ROIS_CORTICOTROP.ls()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of ROIs\n",
    "len(ROIS_CORTICOTROP.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tile_paths_corticotrop_1 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_CORTICOTROP_1.ls()) if p.suffix == '.png']\n",
    "tile_paths_corticotrop_2 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_CORTICOTROP_2.ls()) if p.suffix == '.png']\n",
    "tile_paths_corticotrop_3 = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_CORTICOTROP_3.ls()) if p.suffix == '.png']\n",
    "\n",
    "\n",
    "tile_paths_all_corticotrop = tile_paths_corticotrop_1 \\\n",
    "                            + tile_paths_corticotrop_2 \\\n",
    "                            + tile_paths_corticotrop_3 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of cases, tiles have been extracted from\n",
    "len(set([get_id_from_path(p) for p in tile_paths_all_corticotrop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tile_paths_all_corticotrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create pandas dataframe with tile information to later extract tiles on the fly from WSIs during training (use this, if you do not have extracted tiles saved on disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiles_df_path = PATH/'tiles_info-tile_score_thresh=0.4-tiles.scoring_function_1.csv'\n",
    "\n",
    "\n",
    "if os.path.isfile(tiles_df_path):\n",
    "    ###\n",
    "    # just load from disc, if you have already calculated tile infos before\n",
    "    ###\n",
    "    tiles_df = pd.read_csv(tiles_df_path).set_index('tile_name')\n",
    "else:\n",
    "    ###\n",
    "    # generate and save tile info\n",
    "    ###\n",
    "    rois_paths_gonado = [p for p in ROIS_GONADOTROP.ls() if (p.suffix == '.png' and '-HE' in p.name)]\n",
    "    rois_paths_cortico = [p for p in ROIS_GONADOTROP.ls() if (p.suffix == '.png' and '-HE' in p.name)]\n",
    "    rois_paths_all = rois_paths_gonado + rois_paths_cortico\n",
    "    tiles_df = tiles.WsiOrROIToTilesMultithreaded(wsiPaths=rois_paths_all, \n",
    "                                   tilesFolderPath=None, \n",
    "                                   tileHeight=1024, \n",
    "                                   tileWidth=1024, \n",
    "                                   tile_naming_func=tiles.get_roi_name_from_path_pituitary_adenoma_entities, \n",
    "                                   tile_score_thresh=0.4, \n",
    "                                   tileScoringFunction=tiles.scoring_function_1, \n",
    "                                   is_wsi=False, \n",
    "                                   level=0, \n",
    "                                   save_tiles=False)\n",
    "    tiles_df.to_csv(tiles_df_path, index_label='tile_name')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### moving tiles into seperate folders -- obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "#specify test data and move it to a seperate folder (required only once)\n",
    "##\n",
    "#tile_paths_all = [p for p in (TRAIN.ls()) if p.suffix == '.png']\n",
    "#ids = []\n",
    "#for p in tqdm(tile_paths_all):\n",
    "#    ids.append(get_id_from_path(p))\n",
    "#ids = list(set(ids))\n",
    "#train_and_valid_pct = 0.9\n",
    "#test_pct = 0.1\n",
    "#ids_train_and_valid, ids_test = train_test_split(ids, test_size=test_pct, random_state=seed)\n",
    "#\n",
    "###\n",
    "##move test images to extra folder\n",
    "###\n",
    "#for id in tqdm(ids_test):\n",
    "#    for p in tile_paths_all:\n",
    "#        if id in str(p):\n",
    "#            !mv {p} {TEST}\n",
    "\n",
    "##\n",
    "#split remaining images into train and val sets\n",
    "##\n",
    "#tile_paths_train_and_valid = [p for p in (TRAIN.ls()) if p.suffix == '.png']\n",
    "#ids_train_and_val = []\n",
    "#for p in tqdm(tile_paths_train_and_valid):\n",
    "#    ids_train_and_val.append(get_id_from_path(p))       \n",
    "#ids_train_and_val = list(set(ids_train_and_val))\n",
    "#train_pct = 0.8\n",
    "#valid_pct = 0.2\n",
    "#ids_train, ids_val = train_test_split(ids_train_and_val, test_size=valid_pct, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create unique list of case ids and list of all tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Option 1: use this, if you already have extracted tiles saved to disc\n",
    "###\n",
    "case_ids, tile_paths_all = extract_case_ids_from_existing_tiles()\n",
    "\n",
    "###\n",
    "# Option 2: use this, if you only have a dataframe generated in 5.2\n",
    "###\n",
    "#case_ids = list(set([get_id_from_path(p) for p in tiles_df['wsi_path'].tolist()]))\n",
    "#tile_paths_all = tiles_df.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Option 1: split cases and the associated tiles into train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_and_valid_pct = 0.9\n",
    "test_pct = 0.1\n",
    "ids_train_and_valid, ids_test = train_test_split(case_ids, test_size=test_pct, random_state=seed)\n",
    "\n",
    "valid_pct = 0.2\n",
    "ids_train, ids_val = train_test_split(ids_train_and_valid, test_size=valid_pct, random_state=seed)\n",
    "\n",
    "tile_paths_train = [p for p in tile_paths_all if get_id_from_path(p) in ids_train]\n",
    "tile_paths_val = [p for p in tile_paths_all if get_id_from_path(p) in ids_val]\n",
    "tile_paths_test = [p for p in tile_paths_all if get_id_from_path(p) in ids_test]\n",
    "\n",
    "df_tile_paths_train_and_valid = pd.DataFrame((tile_paths_train+tile_paths_val), columns=['name'])\n",
    "\n",
    "print(f'seed: {seed}')\n",
    "print(len(tile_paths_train))\n",
    "print(len(tile_paths_val))\n",
    "print(len(tile_paths_test))\n",
    "print(len(ids_train))\n",
    "print(len(ids_val))\n",
    "print(len(ids_test))\n",
    "print(len(ids_train+ids_val+ids_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: n-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 2\n",
    "n_splits = 5\n",
    "\n",
    "###\n",
    "# Also generating y-labels for stratified splits, but that's very hard to decide for a multilabel classification\n",
    "# (sklearn.model_selection.StratifiedKFold)\n",
    "###\n",
    "\n",
    "##key = tile_path:string; value = labels:list[ints]\n",
    "#tiles_paths_to_labels = {}\n",
    "#for p in tile_paths_all:\n",
    "#    lb = label_func(p)\n",
    "#    assert not((1 in lb or 3 in lb) and (8 in lb or 9 in lb)) and len(lb) < 3\n",
    "#    tiles_paths_to_labels[p] = lb\n",
    "#\n",
    "##key = id:string; value = labels:list[ints]\n",
    "#case_id_to_labels = {}\n",
    "#for p in tiles_paths_to_labels:\n",
    "#    lb_tile = tiles_paths_to_labels[p]\n",
    "#    case_id = get_id_from_path(p)   \n",
    "#    if(case_id in case_id_to_labels):\n",
    "#        case_id_to_labels[case_id] += lb_tile\n",
    "#    else:\n",
    "#        case_id_to_labels[case_id] = lb_tile\n",
    "#    lb_case_id = case_id_to_labels[case_id]\n",
    "#    assert not((1 in lb_case_id or 3 in lb_case_id) and (8 in lb_case_id or 9 in lb_case_id)) and len(lb_case_id) < 3   \n",
    "#\n",
    "#x_case_id_indices = list(range(len(case_id_to_labels)));x_case_id_indices    \n",
    "#\n",
    "#def one_hot_encode(labels:list, all_classes:list = lbs2num.values()):\n",
    "#    for c in labels:\n",
    "#        assert c in all_classes\n",
    "#    n = len(all_classes)\n",
    "#    res = np.zeros(n, int)\n",
    "#    for i, c in enumerate(all_classes):\n",
    "#        if c in labels:\n",
    "#            res[i] = 1 \n",
    "#    return res\n",
    "#\n",
    "#y = np.zeros(shape=(len(case_id_to_labels),len(lbs2num.values())))\n",
    "#for n, case_id in enumerate(case_ids):\n",
    "#    y[n] = one_hot_encode(case_id_to_labels[case_id])\n",
    "\n",
    "\n",
    "x_case_id_indices = list(range(len(case_ids)))\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "splits = kf.split(x_case_id_indices)\n",
    "split_current_iteration = list(splits)[iteration]\n",
    "\n",
    "train_indices = split_current_iteration[0]\n",
    "val_indices = split_current_iteration[1]\n",
    "\n",
    "ids_train = [case_ids[i] for i in train_indices]\n",
    "ids_val = [case_ids[i] for i in val_indices]\n",
    "\n",
    "df_tile_paths_train_and_valid = pd.DataFrame(tile_paths_all, columns=['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True)\n",
    "\n",
    "#for t in tfms[0]:\n",
    "#    print(t)\n",
    "#    print(\"--------------------------------------------------------------------------------\")\n",
    "#    \n",
    "#for t in tfms[1]:\n",
    "#    print(t)\n",
    "#    print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "#tfms = ([RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True),\n",
    "#        RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.475, 0.525)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "#        RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.95, 1.0526315789473684)}, p=0.75, resolved={}, do_run=True, is_random=True)],\n",
    "#        [])\n",
    "\n",
    "#def get_ex(): return open_image(str(TRAIN.ls()[0]))\n",
    "#\n",
    "#def plots_f(rows, cols, width, height, **kwargs):\n",
    "#    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n",
    "#        rows,cols,figsize=(width,height))[1].flatten())]\n",
    "#\n",
    "#plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datablock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# if you use a pandas dataframe generated in 5.2 to extract tiles on the fly during training, \n",
    "# overwrite fastai.vision.data.ImageList.open and fastai.vision.image.open_image\n",
    "###\n",
    "\n",
    "#here we already have extracted tiles and would need to extract from ROIs (large .png file), which is pretty slow.\n",
    "#for a working example, where tiles get extracted from WSIs on the fly, see the network-relapse_classification.ipynb\n",
    "\n",
    "#def open_custom(self, fn):\n",
    "#    \"Open image in `fn`.\"\n",
    "#    return open_image_custom(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "#\n",
    "#def open_image_custom(fn:PathOrStr, \n",
    "#                      div:bool=True, \n",
    "#                      convert_mode:str='RGB', \n",
    "#                      cls:type=fastai.vision.Image, \n",
    "#                      after_open:Callable=None)->fastai.vision.Image:\n",
    "#        \"Open image in `fn`.\"\n",
    "#        fn = Path(fn)\n",
    "#        tile_name = fn.name\n",
    "#        row = tiles_df.loc[tile_name, : ]\n",
    "#        wsi_path = row['wsi_path']\n",
    "#        x = row['x_upper_left']\n",
    "#        y = row['y_upper_left']\n",
    "#        width = row['pixels_width']\n",
    "#        height = row['pixels_height']\n",
    "#        tile = tiles.ExtractTileFromPILImage(path=wsi_path, x=x, y=y, width=width, height=height)\n",
    "#        tile = tile.convert(convert_mode)\n",
    "#        if after_open: \n",
    "#            tile = after_open(tile)\n",
    "#        tile = pil2tensor(tile,np.float32)\n",
    "#        if div: \n",
    "#            tile.div_(255)\n",
    "#        return cls(tile)\n",
    "#        \n",
    "#fastai.vision.data.ImageList.open = open_custom\n",
    "#fastai.vision.image.open_image = open_image_custom\n",
    "\n",
    "nw = 16   #number of workers for data loader\n",
    "\n",
    "def split_func(path):\n",
    "    path = Path(path)\n",
    "    return get_id_from_path(path) in ids_val\n",
    "\n",
    "#data = ImageList.from_folder(path=TRAIN, extensions=['.png'])\n",
    "data = ImageList.from_df(df_tile_paths_train_and_valid, path=PATH)\n",
    "data = data.split_by_valid_func(split_func)\n",
    "data = data.label_from_func(label_func)\n",
    "data = data.transform(tfms=tfms, size=sz)\n",
    "#data = data.add_test_folder(test_folder=TEST_EXPERIMENTING)\n",
    "#data = data.add_test([PATH/p for p in tile_paths_test])\n",
    "temporary_training_path = PATH/f'models/{n}-resnext_currently_training_cross-valid-iteration-{iteration}'\n",
    "data = data.databunch(bs=bs, num_workers=nw, path=temporary_training_path)\n",
    "data = data.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_frozen = 5\n",
    "epochs_unfrozen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnext101_32x8d\n",
    "learner = cnn_learner(data=data, \n",
    "                     base_arch=arch, \n",
    "                     metrics=[accuracy_thresh], \n",
    "                     ps=dropout, \n",
    "                     pretrained=True, \n",
    "                     wd = wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nameBase = f'{n}-{arch.__name__}-size{sz}-bs{bs}-epochs_head{epochs_frozen}-epochs_complete{epochs_unfrozen}-seed_{seed}-test_pct_{test_pct}-valid_pct_{valid_pct}-with_tiles_gonadotrop2_and_corticotrop2'\n",
    "valid_pct = len(ids_val)/len(case_ids)\n",
    "nameBase = f'{n}-{arch.__name__}-size{sz}-bs{bs}-epochs_head{epochs_frozen}-epochs_complete{epochs_unfrozen}-seed_{seed}-valid_pct_{valid_pct}-n_splits_{n_splits}-tiles_1+2+3-cross_valid_iteration_{iteration}'\n",
    "nameBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(start_lr=1e-10, end_lr=10, num_it=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(cyc_len=epochs_frozen, max_lr=lr, \n",
    "                      callbacks=[SaveModelCallback(learner, \n",
    "                                                   every='epoch', monitor='accuracy_thresh', \n",
    "                                                   name='bestmodel_head')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameHead = f'{nameBase}-head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(nameHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load(nameHead)\n",
    "learner.load('bestmodel_head_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(start_lr=1e-12, end_lr=10, num_it=10000)\n",
    "learner.recorder.plot(skip_start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = 1e-7\n",
    "lr3 = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(cyc_len=epochs_unfrozen, \n",
    "                      max_lr=slice(lr2, lr3), \n",
    "                      callbacks=[SaveModelCallback(learner, \n",
    "                                                   every='epoch', \n",
    "                                                   monitor='accuracy_thresh', \n",
    "                                                   name='bestmodel_lr2=1e-7--lr3=1e-6')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameComplete = f'{nameBase}-complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.save(nameComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.load(nameComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load('bestmodel_9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction per case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(predicted_classes:list, all_classes:list):\n",
    "    for c in predicted_classes:\n",
    "        assert c in all_classes\n",
    "    n = len(all_classes)\n",
    "    res = np.zeros(n, int)\n",
    "    for i, c in enumerate(all_classes):\n",
    "        if c in predicted_classes:\n",
    "            res[i] = 1 \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_predict(dict_arch_to_path_of_saved_model:typing.Dict[Callable, pathlib.Path], \n",
    "                     data:fastai.vision.data.ImageDataBunch,\n",
    "                     ds_type:fastai.basic_data.DatasetType,\n",
    "                     tta:bool, \n",
    "                     scale:float,\n",
    "                     beta:float):\n",
    "    \"\"\"\n",
    "    tta: Should test time augmentation be used?\n",
    "    scale: if tta is True -> scaling factor for tta\n",
    "    beta: if tta is True -> beta factor for tta\n",
    "    check this out for more infos: https://docs.fast.ai/basic_train.html#Test-time-augmentation\n",
    "    \"\"\"\n",
    "   \n",
    "    print(f'{str([a.__name__ for a in dict_arch_to_path_of_saved_model.keys()])}_sz{sz}_ensembled')\n",
    "    \n",
    "    predsList = []\n",
    "    for arch in dict_arch_to_path_of_saved_model.keys():\n",
    "        learner = cnn_learner(data=data, base_arch=arch, pretrained=False)\n",
    "        learner.load(dict_arch_to_path_of_saved_model[arch])\n",
    "        if tta is True:\n",
    "            preds = learner.TTA(beta=beta, scale=scale, ds_type=ds_type)\n",
    "        else:\n",
    "            preds = learner.get_preds(ds_type=ds_type)\n",
    "            \n",
    "        predsList.append(preds)\n",
    "    \n",
    "    preds_ensembled = predsList[0]\n",
    "    for n, _ in enumerate(predsList):\n",
    "        if n == 0:\n",
    "            continue\n",
    "        else:\n",
    "            preds_ensembled[0] = preds_ensembled[0] + predsList[n][0]\n",
    "    preds_ensembled[0] = preds_ensembled[0]/len(predsList)\n",
    "    \n",
    "    return preds_ensembled\n",
    "\n",
    "def from_preds_to_dict_path_to_preds(preds, \n",
    "                                     imageDataBunch:fastai.vision.ImageDataBunch, \n",
    "                                     ds_type:fastai.basic_data.DatasetType,\n",
    "                                     threshold:float):\n",
    "    \"\"\"\n",
    "    preds: What fastai.vision.learner.get_preds or fastai.vision.learner.TTA return.\n",
    "            two tensors: 1st: lists with raw predictions for each class of an image\n",
    "                         2nd: lists with y_true\n",
    "            form e.g. [tensor([[0.9672, 0.9211, 0.4560, 0.8185], \n",
    "                                [0.9498, 0.8600, 0.5852, 0.7206]]),\n",
    "                         tensor([[0., 0., 0., 1.],\n",
    "                                [0., 0., 1., 1.]])]\n",
    "    threshold:  threshold to consider the predictions per tile to be correct or not\n",
    "                                \n",
    "    RETURN:\n",
    "        key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "        e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    \"\"\"\n",
    "    #key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "    #e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    d = None\n",
    "    if ds_type is DatasetType.Valid:\n",
    "        d = imageDataBunch.valid_ds\n",
    "    elif ds_type is DatasetType.Test:\n",
    "        d = imageDataBunch.test_ds\n",
    "    elif ds_type is DatasetType.Train:\n",
    "        d = imageDataBunch.train_ds\n",
    "    for path, pred in tqdm(zip(d.items, preds[0]), total = len(d.items)):\n",
    "        multi_c = None\n",
    "        pred_one_hot_encoded = (pred > threshold).float()\n",
    "        pred_raw = pred\n",
    "        path_to_pred[path] = multi_c, pred_one_hot_encoded, pred_raw\n",
    "        \n",
    "    return path_to_pred\n",
    "\n",
    "\n",
    "def get_class_occurence_per_id(learner:fastai.vision.learner=None,\n",
    "                               labelList:fastai.data_block.LabelList=None,\n",
    "                               dict_arch_to_path_of_saved_model:typing.Dict[Callable, pathlib.Path]=None,\n",
    "                               imageDataBunch:fastai.vision.data.ImageDataBunch=None,\n",
    "                               ds_type:fastai.basic_data.DatasetType=None,\n",
    "                               tta:bool=False,                                          \n",
    "                               threshold = 0.5,                              \n",
    "                               scale:float = 1.35,\n",
    "                               beta: float = 0.4):\n",
    "    \"\"\"\n",
    "    Option 1: Hand over a fastai.vision.learner and fastai.data_block.LabelList. No tta and no ensembling available\n",
    "                for this option.\n",
    "    Option 2: Hand over a fastai.vision.learner that was initalized with a fastai.vision.data.ImageDataBunch object.\n",
    "    Option 3: Hand over dict where the keys are functions to create a model (e.g. torchvision.models.resnet50)\n",
    "                and the values are paths to saved weights. Do this to use ensembling.\n",
    "    \n",
    "    Params:\n",
    "        threshold:  threshold to consider the predictions per tile to be correct or not\n",
    "        scale: only needed when tta is True; scale value for fastai's fastai.basic_train.Learner.TTA function\n",
    "        beta: only needed when tta is True; beta value for fastai's fastai.basic_train.Learner.TTA function\n",
    "    \"\"\"\n",
    "    \n",
    "    if labelList is not None and ds_type is not None:\n",
    "        raise ValueError('One of dataset or ds_type must be None')\n",
    "    if labelList is not None and tta is True:\n",
    "        raise ValueError('TTA is not available for a custom LabelList')\n",
    "                \n",
    "    #key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "    #e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    \n",
    "    #Option 1\n",
    "    if learner is not None and labelList is not None:\n",
    "        for n, path in tqdm(enumerate(labelList.items), total=len(labelList.items)):\n",
    "            pred = learner.predict(labelList[n][0], thresh=threshold)\n",
    "            path_to_pred[path] = pred\n",
    "    \n",
    "    #Option 2\n",
    "    elif learner is not None and labelList is None and  not dict_arch_to_path_of_saved_model and imageDataBunch is None:\n",
    "        if tta is True:\n",
    "            preds = learner.TTA(beta=beta, scale=scale, ds_type=ds_type)\n",
    "        else:\n",
    "            preds = learner.get_preds(ds_type=ds_type)\n",
    "        path_to_pred = from_preds_to_dict_path_to_preds(preds, learner.data, ds_type, threshold)\n",
    "                \n",
    "    #Option 3\n",
    "    elif dict_arch_to_path_of_saved_model and imageDataBunch is not None:\n",
    "        preds = ensemble_predict(dict_arch_to_path_of_saved_model, imageDataBunch, ds_type, tta, scale, beta)\n",
    "        path_to_pred = from_preds_to_dict_path_to_preds(preds, imageDataBunch, ds_type, threshold)                \n",
    "               \n",
    "    #key: id of a case; value: list with this syntax  \n",
    "    #[<number of all tiles of one id>, \n",
    "    #[<number of occurence of predicted class1 over all tiles per id>, \n",
    "    #<number of occurence of predicted class2 over all tiles per id>, ..., \n",
    "    #<number of occurence of predicted classN over all tiles per id>],\n",
    "    #y_true_one_hot_encoded]\n",
    "    class_occurence_per_id = {}\n",
    "    \n",
    "    for path, pred in path_to_pred.items():   \n",
    "        id = get_id_from_path(path)\n",
    "        if id in class_occurence_per_id:\n",
    "            v = class_occurence_per_id[id]\n",
    "            v[0] = v[0] + 1\n",
    "            v[1] = v[1] + pred[1]\n",
    "            class_occurence_per_id[id] = v\n",
    "        else:\n",
    "            class_occurence_per_id[id] = [1, pred[1], one_hot_encode(label_func(path), lbs2num.values())]\n",
    "            \n",
    "    return class_occurence_per_id\n",
    "\n",
    "\n",
    "def get_preds_threshold_per_id(thresholds_per_class:list, class_occurence_per_id:dict):\n",
    "    \"\"\"\n",
    "    thresholds_per_class:  list with n = number_of_classes double values, e.g. four classes -> [0.5, 0.5, 0.5, 0.5] \n",
    "                            thresholds per class to consider the predictions per wsi to be correct or not\n",
    "                            example: 100 tiles of one WSI, threshold for class 1 is 0.5, the wsi will get labeled with\n",
    "                                        that class, if more than 50 tiles were labeled with that class by the classifier\n",
    "                                \n",
    "    RETURN:\n",
    "            key: id of a case; \n",
    "            value: list with this syntax  \n",
    "            [y_pred_th e.g. [True,False,False,False], \n",
    "            y_true e.g. [1,0,0,0]]\n",
    "    \"\"\"    \n",
    "    result = {}\n",
    "    for k in class_occurence_per_id.keys():\n",
    "        y_pred_th = []\n",
    "        for n, i in enumerate(class_occurence_per_id[k][1]):\n",
    "            i = int(i)\n",
    "            y_pred_th.append(i/class_occurence_per_id[k][0] > thresholds_per_class[n])\n",
    "    \n",
    "        result[k] = [y_pred_th, class_occurence_per_id[k][2]]\n",
    "    return result\n",
    "\n",
    "def get_accuracy_over_all_ids(number_of_ids, preds_threshold_per_id:dict, per_class:bool = True, number_of_classes = len(lbs2num)):\n",
    "    if per_class is True:\n",
    "        correctly_predicted = np.zeros(number_of_classes, dtype=np.int)\n",
    "    else:\n",
    "        correctly_predicted = 0\n",
    "    for k in preds_threshold_per_id.keys():\n",
    "        pred = preds_threshold_per_id[k][0]\n",
    "        true = preds_threshold_per_id[k][1]\n",
    "        for i in range(number_of_classes):\n",
    "            if true[i] == pred[i]:\n",
    "                if per_class is True:\n",
    "                    correctly_predicted[i] = correctly_predicted[i] + 1\n",
    "                else:\n",
    "                    correctly_predicted = correctly_predicted + 1\n",
    "    if per_class is True:                    \n",
    "        correctly_predicted_percentage = {}\n",
    "        for lb, num in zip(lbs2num.keys(), correctly_predicted):\n",
    "            correctly_predicted_percentage[lb] = num/number_of_ids\n",
    "    if per_class is False:\n",
    "        correctly_predicted_percentage = correctly_predicted/number_of_ids\n",
    "\n",
    "    return correctly_predicted_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arches = {resnext101_32x8d:Path(MODEL_PATH/'6-resnext101_32x8d-size512-bs8-seed_73/bestmodel_15'),\n",
    "          se_resnext101_32x4d:MODEL_PATH/'11-se_resnext101_32x4d-size512-bs10-epochs_head5-epochs_complete5-seed_73/11-se_resnext101_32x4d-size512-bs8-epochs_head5-epochs_complete5-seed_73-complete'}\n",
    "\n",
    "ths = [0.5,0.5,0.5,0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n = 13\n",
    "saved_model_names = ['bestmodel_lr2=1e-7--lr3=1e-6_2nd_run_9', 'bestmodel_lr2=1e-7--lr3=1e-6_9', 'bestmodel_lr2=1e-7--lr3=1e-6_9', 'bestmodel_lr2=1e-7--lr3=1e-6_9', 'bestmodel_lr2=1e-7--lr3=1e-6_9']\n",
    "copi_val = None\n",
    "separated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iteration in tqdm(range(n_splits)):\n",
    "    x_case_id_indices = list(range(len(case_ids)))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    splits = kf.split(x_case_id_indices)\n",
    "    split_current_iteration = list(splits)[iteration]\n",
    "    train_indices = split_current_iteration[0]\n",
    "    val_indices = split_current_iteration[1]\n",
    "    ids_train = [case_ids[i] for i in train_indices]\n",
    "    ids_val = [case_ids[i] for i in val_indices]\n",
    "    df_tile_paths_train_and_valid = pd.DataFrame(tile_paths_all, columns=['name'])\n",
    "    \n",
    "    tfms = get_transforms(flip_vert=True)\n",
    "\n",
    "    df_c = pd.read_excel(LABELS_CORTICOTROP)\n",
    "    \n",
    "    nw = 16   #number of workers for data loader\n",
    "    \n",
    "    def split_func(path):\n",
    "        path = Path(path)\n",
    "        return get_id_from_path(path) in ids_val\n",
    "    \n",
    "    data = ImageList.from_df(df_tile_paths_train_and_valid, path=PATH)\n",
    "    data = data.split_by_valid_func(split_func)\n",
    "    data = data.label_from_func(label_func)\n",
    "    data = data.transform(tfms=tfms, size=sz)\n",
    "    temporary_training_path = PATH/f'models/{n}-resnext_currently_training_cross-valid-iteration-{iteration}'\n",
    "    data = data.databunch(bs=bs, num_workers=nw, path=temporary_training_path)\n",
    "    data = data.normalize()\n",
    "\n",
    "    arch = resnext101_32x8d\n",
    "    learner = cnn_learner(data=data, \n",
    "                         base_arch=arch, \n",
    "                         metrics=[accuracy_thresh], \n",
    "                         ps=dropout, \n",
    "                         pretrained=True, \n",
    "                         wd = wd)\n",
    "\n",
    "    learner.load(saved_model_names[iteration])\n",
    "\n",
    "    copi_val_current = get_class_occurence_per_id(learner=learner, ds_type=DatasetType.Valid, tta=False)\n",
    "\n",
    "    if separated:\n",
    "        if copi_val is None:\n",
    "            copi_val = []\n",
    "            copi_val.append(copi_val_current)\n",
    "        else:\n",
    "            copi_val.append(copi_val_current)\n",
    "    else:\n",
    "        if copi_val is None:\n",
    "            copi_val = copi_val_current\n",
    "        else:\n",
    "            copi_val = {**copi_val, **copi_val_current}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copi_val_save_name = \"13-5_fold_cross_validation-copi_val-separated=True.pkl\"\n",
    "copi_val_save_name = \"13-5_fold_cross_validation-copi_val-separated=False.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# save it to disc as pickle file\n",
    "###\n",
    "import pickle\n",
    "f = open(f'{copi_val_save_name}',\"wb\")\n",
    "pickle.dump(copi_val,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# load it from disc\n",
    "###\n",
    "f = open(copi_val_save_name,'rb')\n",
    "copi_val = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thresholded accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if separated:\n",
    "    copi_val_all = copi_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if separated:\n",
    "    i=4\n",
    "    copi_val = copi_val_all[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_th_val = get_preds_threshold_per_id(ths, copi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_per_class_val = get_accuracy_over_all_ids(len(preds_th_val), preds_th_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc_curves and probability histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['acth', 'silent', 'lh', 'fsh']\n",
    "class_numbers = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for class_name, class_number in zip(class_names, class_numbers):\n",
    "    ###\n",
    "    # roc_curve\n",
    "    ###\n",
    "    y_preds = []\n",
    "    y_true = []\n",
    "    for key, value in copi_val.items():\n",
    "        #calculate prediction score for {class_name}\n",
    "        n_tiles_all = value[0]\n",
    "        n_tiles_class = value[1][class_number]\n",
    "        percentage = n_tiles_class/n_tiles_all\n",
    "        y_preds.append(percentage)\n",
    "        \n",
    "        #true label for {class_name}\n",
    "        y_true.append(value[2][class_number])\n",
    "        \n",
    "    \n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_preds, pos_label=1)\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.title(f'Receiver Operating Characteristic for {class_name}')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # histogram\n",
    "    ###\n",
    "    #predicted probabilities for {class_name} for WSIs, that were really {class_name}\n",
    "    probs_true_positive = []\n",
    "    #predicted probabilities for {class_name} for WSIs, that were really not {class_name}\n",
    "    probs_true_negative =[]\n",
    "    for key, value in copi_val.items():\n",
    "        #calculate prediction score for {class_name}\n",
    "        n_tiles_all = value[0]\n",
    "        n_tiles_class = value[1][class_number]\n",
    "        percentage = n_tiles_class/n_tiles_all\n",
    "        if value[2][class_number] == 1:\n",
    "            probs_true_positive.append(percentage)\n",
    "        else:\n",
    "            probs_true_negative.append(percentage)\n",
    "    \n",
    "    from matplotlib import pyplot\n",
    "    \n",
    "    bins = np.linspace(0, 1, 50)\n",
    "    \n",
    "    pyplot.hist(probs_true_positive, bins, alpha=0.5, label='true positive')\n",
    "    pyplot.hist(probs_true_negative, bins, alpha=0.5, label='true negative')\n",
    "    pyplot.legend(loc='upper right')\n",
    "    pyplot.title(label=class_name)\n",
    "    pyplot.ylabel('Frequency')\n",
    "    pyplot.xlabel('Predicted Probability')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'gonadotropic'\n",
    "class_number_lh = 2 \n",
    "class_number_fsh = 3\n",
    "\n",
    "###\n",
    "# roc_curve\n",
    "###\n",
    "y_preds = []\n",
    "y_true = []\n",
    "for key, value in tqdm(copi_val.items()):\n",
    "    #calculate prediction score for {class_name}\n",
    "    n_tiles_all = value[0]\n",
    "    if value[1][class_number_lh] > value[1][class_number_fsh]:\n",
    "        n_tiles_class = value[1][class_number_lh]\n",
    "    else:\n",
    "        n_tiles_class = value[1][class_number_fsh]\n",
    "\n",
    "    percentage = n_tiles_class/n_tiles_all\n",
    "    y_preds.append(percentage)\n",
    "    \n",
    "    #true label for {class_name}\n",
    "    y_true.append(int(value[2][class_number_lh] == 1 or value[2][class_number_fsh] == 1))\n",
    "    \n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_preds, pos_label=1)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title(f'Receiver Operating Characteristic for {class_name}')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###\n",
    "# histogram\n",
    "###\n",
    "#predicted probabilities for {class_name} for WSIs, that were really {class_name}\n",
    "probs_true_positive = []\n",
    "#predicted probabilities for {class_name} for WSIs, that were really not {class_name}\n",
    "probs_true_negative =[]\n",
    "for key, value in tqdm(copi_val.items()):\n",
    "    #calculate prediction score for {class_name}\n",
    "    n_tiles_all = value[0]\n",
    "    if value[1][class_number_lh] > value[1][class_number_fsh]:\n",
    "        n_tiles_class = value[1][class_number_lh]\n",
    "    else:\n",
    "        n_tiles_class = value[1][class_number_fsh]\n",
    "    percentage = n_tiles_class/n_tiles_all\n",
    "    if value[2][class_number_lh] == 1 or value[2][class_number_fsh] == 1:\n",
    "        probs_true_positive.append(percentage)\n",
    "    else:\n",
    "        probs_true_negative.append(percentage)\n",
    "   \n",
    "from matplotlib import pyplot\n",
    "   \n",
    "bins = np.linspace(0, 1, 50)\n",
    "   \n",
    "pyplot.hist(probs_true_positive, bins, alpha=0.5, label='true positive')\n",
    "pyplot.hist(probs_true_negative, bins, alpha=0.5, label='true negative')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.title(label=class_name)\n",
    "pyplot.ylabel('Frequency')\n",
    "pyplot.xlabel('Predicted Probability')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### seed 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#copi_test = get_class_occurence_per_id(dict_arch_to_path_of_saved_model=arches,\n",
    "#                                      imageDataBunch=data,\n",
    "#                                      ds_type=DatasetType.Test)\n",
    "copi_test = get_class_occurence_per_id(learner=learner, ds_type=DatasetType.Test, tta=False)\n",
    "preds_th_test = get_preds_threshold_per_id(ths, copi_test)\n",
    "accuracy_per_class_test = get_accuracy_over_all_ids(len(preds_th_test), preds_th_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy_per_class_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_confusion_matrix(self, slice_size:int=1):\n",
    "        \"Confusion matrix as an `np.ndarray`.\"\n",
    "        x=torch.arange(0,self.data.c)\n",
    "        if slice_size is None: cm = ((self.pred_class==x[:,None]) & (self.y_true==x[:,None,None])).sum(2)\n",
    "        else:\n",
    "            cm = torch.zeros(self.data.c, self.data.c, dtype=x.dtype)\n",
    "            for i in range(0, self.y_true.shape[0], slice_size):\n",
    "                #cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n",
    "                            #& (self.y_true[i:i+slice_size]==x[:,None,None])).sum(2)\n",
    "                cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n",
    "                            & (self.y_true[i:i+slice_size]==(x[:,None,None]).float())).sum(2)\n",
    "                torch.add(cm, cm_slice, out=cm)\n",
    "        return to_np(cm)\n",
    "    \n",
    "fastai.train.ClassificationInterpretation.confusion_matrix = custom_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM Py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "405px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
